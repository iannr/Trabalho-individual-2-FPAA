# MaxMin Select â€” SeleÃ§Ã£o SimultÃ¢nea do Maior e do Menor (DivisÃ£o e Conquista)

Este repositÃ³rio implementa, em Python, o algoritmo de seleÃ§Ã£o simultÃ¢nea do maior e do menor elementos de uma sequÃªncia (tambÃ©m chamado MaxMin Select), utilizando a tÃ©cnica de divisÃ£o e conquista. O objetivo Ã© reduzir o nÃºmero de comparaÃ§Ãµes em relaÃ§Ã£o Ã  abordagem ingÃªnua, encontrando min e max em uma Ãºnica passada recursiva.
---

## ğŸ“¦ Estrutura
```
.
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ recursion_tree.png
â”œâ”€â”€ main.py
â””â”€â”€ README.md
```

---

## ğŸš€ Como executar


```bash
# 1) Clonar o repositÃ³rio 

# 2) Executar com argumentos (nÃºmeros separados por espaÃ§o)
python main.py 7 3 9 1 4

# ou, sem numeros ai vai gerar aleatorio
python main.py
```

---

## ğŸ§  Ideia do algoritmo (linha a linha)

Trecho principal (`_max_min_dc`):

```py
def _max_min_dc(a, lo, hi):
    length = hi - lo + 1

    # Caso base 1: um elemento â†’ (x, x), 0 comparaÃ§Ãµes.
    if length == 1:
        x = a[lo]
        return (x, x)

    # Caso base 2: dois elementos â†’ 1 comparaÃ§Ã£o para ordenÃ¡-los.
    if length == 2:
        x, y = a[lo], a[hi]
        if x <= y:
            return (x, y)
        else:
            return (y, x)

    # Divide em duas metades
    mid = (lo + hi) // 2

    # Conquista: resolve recursivamente em cada metade
    minL, maxL = _max_min_dc(a, lo, mid)
    minR, maxR = _max_min_dc(a, mid + 1, hi)

    # Combina (2 comparaÃ§Ãµes): maior entre os mÃ¡ximos; menor entre os mÃ­nimos
    if maxL >= maxR:
        overall_max = maxL
    else:
        overall_max = maxR

    if minL <= minR:
        overall_min = minL
    else:
        overall_min = minR

    return (overall_min, overall_max)
```

**ExplicaÃ§Ã£o passo a passo:**  
1. **Casos base:** evitam recursÃµes desnecessÃ¡rias e fixam a contagem de comparaÃ§Ãµes:  
   - 1 elemento: retorna o prÃ³prio valor como `(min, max)` sem comparar.  
   - 2 elementos: uma Ãºnica comparaÃ§Ã£o decide quem Ã© menor/maior.  
2. **Dividir:** parte o intervalo em duas metades quase iguais.  
3. **Conquistar:** calcula `(min, max)` de cada metade recursivamente.  
4. **Combinar:** realiza **2 comparaÃ§Ãµes** totais:  
   - `maxL` vs `maxR` â†’ define `overall_max` (1 comparaÃ§Ã£o);  
   - `minL` vs `minR` â†’ define `overall_min` (1 comparaÃ§Ã£o).

Essa combinaÃ§Ã£o fixa um **teto de 2 comparaÃ§Ãµes** por nÃ³ interno na Ã¡rvore de recursÃ£o.

---

## ğŸ“ˆ AnÃ¡lise por contagem de operaÃ§Ãµes (comparaÃ§Ãµes)

Seja `C(n)` o nÃºmero de **comparaÃ§Ãµes** entre chaves (valores dos dados). Consideramos:
- `C(1) = 0` (um Ãºnico elemento);  
- `C(2) = 1` (uma comparaÃ§Ã£o para ordenar o par);  
- Para `n > 2`, dividimos em duas metades de tamanhos `âŒŠn/2âŒ‹` e `âŒˆn/2âŒ‰` e **combinamos** com **2 comparaÃ§Ãµes** (mÃ¡ximo dos mÃ¡ximos e mÃ­nimo dos mÃ­nimos).

EntÃ£o,
```
C(n) = C(âŒŠn/2âŒ‹) + C(âŒˆn/2âŒ‰) + 2,      para n â‰¥ 3
C(1) = 0,  C(2) = 1.
```

Para `n = 2^k` (potÃªncia de 2), as metades sÃ£o sempre iguais e obtemos:
```
C(n) = 2 C(n/2) + 2,   C(1)=0  â‡’  C(n) = 2n - 2.
```
Logo, o algoritmo realiza **2n âˆ’ 2** comparaÃ§Ãµes para `n = 2^k`. Para `n` arbitrÃ¡rio, o valor fica **â‰¤ 2n âˆ’ 2** (pode ser mostrado por induÃ§Ã£o fraca ou pela estrutura da Ã¡rvore de recursÃ£o que possui `nâˆ’1` nÃ³s internos, cada um contribuindo com 2 comparaÃ§Ãµes). Portanto, a complexidade **assintÃ³tica** por contagem Ã© **Î˜(n)**.

> IntuiÃ§Ã£o pela Ã¡rvore de recursÃ£o: existem `n` folhas (cada uma correspondendo a um elemento) e `nâˆ’1` nÃ³s internos. Como cada nÃ³ interno realiza **2 comparaÃ§Ãµes**, temos no total `2(nâˆ’1) = 2nâˆ’2` comparaÃ§Ãµes.

O diagrama abaixo ilustra os **nÃ­veis** da recursÃ£o e o custo de **combinaÃ§Ã£o** por nÃ­vel:

![Recursion Tree](assets/recursion_tree.png)

---

## ğŸ“š AnÃ¡lise pelo Teorema Mestre

Escrevendo a recorrÃªncia para o tempo total (nÃºmero de operaÃ§Ãµes com custo constante em cada nÃ³ interno):  
\[ T(n) = 2\,T(n/2) + \Theta(1). \]

1. **ParÃ¢metros**:  
   - \(a = 2\) (duas chamadas recursivas),
   - \(b = 2\) (subproblemas de tamanho \(n/2\)),
   - \(f(n) = \Theta(1)\).

2. **Expoente**: \(p = \log_b a = \log_2 2 = 1.\)

3. **Caso do Teorema Mestre**: \(f(n) = O(n^{p-\varepsilon})\) com \(\varepsilon = 1\) (pois \(\Theta(1) = O(n^{0})\) e \(0 = p-1\)).  
   Portanto, **Caso 1** do Teorema Mestre.

4. **SoluÃ§Ã£o**: \(T(n) = \Theta(n).\)

ConclusÃ£o: tempo **linear** no tamanho da entrada.

---

## ğŸ“ ReferÃªncias rÃ¡pidas

- AULA 00â€“03 do curso (complexidade assintÃ³tica, contagem de operaÃ§Ãµes, recorrÃªncias e tÃ©cnicas de projeto).
- Teorema Mestre para T(n)=aT(n/b)+f(n).
